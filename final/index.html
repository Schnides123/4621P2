<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>CS 4621: Final</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/cs4620.css" rel="stylesheet">
    <link href="css/jquery-ui.min.css" rel="stylesheet">
    <link href="css/jquery-ui.theme.min.css" rel="stylesheet">
    <link href="css/jquery-ui.structure.min.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
   <style>
    table, th, td {
        border: 1px solid black;
    }
    th, td {
        min-width: 200px;
        padding: 5px;
    }
    h4 {
        color: white;
    }
    </style>

	<script type="text/javascript">
var floorTexture;
var webcamTexture;
var time = new Date();
var audioCtx = new (window.AudioContext || window.webkitAudioContext)(); // define audio context

var analyser = audioCtx.createAnalyser();
var distortion = audioCtx.createWaveShaper();
var gainNode = audioCtx.createGain();

var treble = audioCtx.createBiquadFilter();
treble.type = "highshelf";
treble.frequency.value = 2000;
//treble.gain.value = treble;

var bass = audioCtx.createBiquadFilter();
bass.type = "lowshelf";
bass.frequency.value = 200;
//bass.gain.value = bass;

var biquadFilter = audioCtx.createBiquadFilter();
analyser.fftSize = 512;
var bufferLength = analyser.frequencyBinCount; // half the FFT value
var buff = new Uint8Array(bufferLength);
var imageData;
var micSource;
var fileSource;

navigator.getUserMedia (
  // constraints - only audio needed for this app
  {
    audio: true,
    video: true
  },

  // Success callback
  function(stream) {
    video = document.getElementById("v");
    video.srcObject = stream;
    video.play();

    audio = new Audio();
    audio.src = "./song.mp3";
    micSource = audioCtx.createMediaStreamSource(stream);
    fileSource = audioCtx.createMediaElementSource(audio);
    source = fileSource;
    source.connect(analyser);
    analyser.connect(distortion);
    distortion.connect(bass);
    bass.connect(treble);
    treble.connect(gainNode);
    //biquadFilter.connect(gainNode);



    gainNode.connect(audioCtx.destination); // connecting the different audio graph nodes together

    // Play the song
    source.mediaElement.play();

    loop(gl, program, vertexBuffer, indexBuffer);
  },

  // Error callback
  function(err) {
    console.log('The following gUM error occured: ' + err);
  }
);
	</script>
</head>
<body>
<div class="container">
    <h1>CS 4621 Final <span class="subtitle">Music Visualization</span></h1>

<div class = "jumbotron" id="canvasdiv">
<canvas id="webglCanvas" style="border: none; background-color: lightgray;" width="600" height="600"></canvas>
<div id="controls" style="float:right;">
    <td>
    <button id="playButton">Play!!</button>
    <td width="20"></td>
    <td>
    <button id="pauseButton">Pause!!</button>
    <td width="20"></td>
    <h4>Volume</h4>
    <input id="volume" type="range" min="0" max="1" step="0.1" value="1.0"/>
    <h4>Treble</h4>
    <input id="treble" type="range" min="0" max="1" step="0.1" value="1.0"/>
    <h4>Bass</h4>
    <input id="bass" type="range" min="0" max="1" step="0.1" value="1.0"/>
    <h4>Biquad Filter</h4>
    <input id="biquad" type="range" min="0" max="22050" step="50" value="500"/>
    <h4>Visualization Mode</h4>
    <select id="mode">
        <option value="frequency">Frequency</option>
        <option value="time">Waveform</option>
    </select>
    <h4>Data Input Mode</h4>
    <select id="inputMode">
        <option value="file">File</option>
        <option value="microphone">Microphone</option>
    </select>
    <h4>Texture Mode</h4>
    <select id="textureMode">
        <option value="images">Images</option>
        <option value="webcam">Webcam</option>
    </select>
</div>
</div>

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
<script src="js/jquery-3.1.1.min.js"></script>
<script src="js/jquery-ui.min.js"></script>
<!-- Data -->
    <script id="vertexShader" type="x-shader/x-vertex">

attribute vec3 vert_position;
attribute vec2 vert_texCoord;
varying vec2 geom_texCoord;

void main() {
    gl_Position = vec4(vert_position, 1.0);
    // vert_texCoord is given in the range ([0,1],[0,1])
    geom_texCoord = vert_texCoord;
}
</script>

<script id="fragmentShader" type="x-shader/x-fragment">
#define MAX_BUFFER 1024
#define PI 3.14159

precision highp float;
varying vec2 geom_texCoord;
uniform sampler2D texture;
uniform sampler2D background;

// The coordinates of the image plane
float x;
float y;

void main() {
    x = geom_texCoord[0];
    y = geom_texCoord[1];
	vec4 fint = texture2D(texture, vec2(x, 0.5));
	if(abs(2.*(y-0.5)) <= fint.x) gl_FragColor = texture2D(background, vec2(x,y));
   	else gl_FragColor = texture2D(texture, vec2(1.-abs(2.*(0.5-y)), 0.5))
					*texture2D(background, vec2(x,y));
}
</script>

<script>
    function createShader(gl, shaderScriptId) {
        var shaderScript = document.getElementById(shaderScriptId);
        var shaderSource = shaderScript.text;
        var shaderType = null;
        if (shaderScript.type == "x-shader/x-vertex") {
            shaderType = gl.VERTEX_SHADER;
        } else if (shaderScript.type == "x-shader/x-fragment") {
            shaderType = gl.FRAGMENT_SHADER;
        } else {
            throw new Error("Invalid shader type: " + shaderScript.type)
        }
        var shader = gl.createShader(shaderType);
        gl.shaderSource(shader, shaderSource);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            var infoLog = gl.getShaderInfoLog(shader);
            gl.deleteShader(shader);
            throw new Error("An error occurred compiling the shader: " + infoLog);
        } else {
            return shader;
        }
    }

    function createGlslProgram(gl, vertexShaderId, fragmentShaderId) {
        var program = gl.createProgram();
        gl.attachShader(program, createShader(gl, vertexShaderId));
        gl.attachShader(program, createShader(gl, fragmentShaderId));
        gl.linkProgram(program);
        gl.validateProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
            var infoLog = gl.getProgramInfoLog(program);
            gl.deleteProgram(program);
            throw new Error("An error occurred linking the program: " + infoLog);
        } else {
            return program;
        }
    }

    function loop(gl, program, vertexBuffer, indexBuffer) {
		if(time.getUTCSeconds() == 0){
			floorImage = new Image();
			floorImage.src = "img/"+(time.getUTCMinutes()%12)+".jpg";
			floorTexture = gl.createTexture();
			gl.bindTexture(gl.TEXTURE_2D, floorTexture);
			gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
			gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, floorImage);
			gl.generateMipmap(gl.TEXTURE_2D);
			gl.bindTexture(gl.TEXTURE_2D, null);

		}
        biquadFilter.frequency.value=document.getElementById("biquad").value;
        bass.frequency.value = document.getElementById("bass").value;
        treble.frequency.value = document.getElementById("treble").value;



        gl.clearColor(0.0, 0.0, 0.0, 0.0);
        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.useProgram(program);

        var tex = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, tex);

        var backgroundTexture;

        if ($("#mode")[0].value == "time") {
            analyser.getByteTimeDomainData(buff);
        } else if ($("#mode")[0].value == "frequency") {
            analyser.getByteFrequencyData(buff);
        }
        if ($("#textureMode")[0].value == "webcam") {
            backgroundTexture = webcamTexture;
        } else if($("#textureMode")[0].value == "images") {
            backgroundTexture = floorTexture;
        }


        var arr = [];
        for (var i = 0; i < analyser.frequencyBinCount; i++) {
          arr.push(buff[i]);
          arr.push(buff[i]);
          arr.push(buff[i]);
          arr.push(255);
        }
        var oneDTextureTexels = new Uint8Array(arr);

        var width = analyser.frequencyBinCount;
        var height = 1;
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, oneDTextureTexels);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
        gl.generateMipmap(gl.TEXTURE_2D);

        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, tex);
        var textureLocation = gl.getUniformLocation(program, "texture");
        gl.uniform1i(textureLocation, 0);

		gl.activeTexture(gl.TEXTURE1);
		gl.bindTexture(gl.TEXTURE_2D, backgroundTexture);
		textureLocation = gl.getUniformLocation(program, "background");
		gl.uniform1i(textureLocation, 1);

        gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
        var vertPositionLocation = gl.getAttribLocation(program, "vert_position");
        gl.enableVertexAttribArray(vertPositionLocation);
        gl.vertexAttribPointer(vertPositionLocation, 3, gl.FLOAT, false, 4*5, 0);
        var vertTextureLocation = gl.getAttribLocation(program, "vert_texCoord");
        gl.enableVertexAttribArray(vertTextureLocation);
        gl.vertexAttribPointer(vertTextureLocation, 2, gl.FLOAT, false, 4*5, 4*3);
        gl.bindBuffer(gl.ARRAY_BUFFER, null);
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);
        gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0);
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null);
        gl.useProgram(null);
        window.requestAnimationFrame(() => { loop(gl, program, vertexBuffer, indexBuffer); });
    }

    let canvas = document.querySelector('#webglCanvas');
    var play = document.querySelector('.play');
    var stop = document.querySelector('.stop');
    let gl = canvas.getContext("webgl");
    let program = createGlslProgram(gl, 'vertexShader', 'fragmentShader');
    let vertexData = [
        -1.0, -1.0, 0.0,  // Lower left
        0.0,  0.0,
        1.0, -1.0, 0.0,  // Lower right
        1.0,  0.0,
        1.0,  1.0, 0.0,  // Top right
        1.0,  1.0,
        -1.0,  1.0, 0.0,  // Top left
        0.0,  1.0
    ];
    let vertexArray = new Float32Array(vertexData);
    let vertexBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, vertexArray, gl.STATIC_DRAW);
    gl.bindBuffer(gl.ARRAY_BUFFER, null);

    // Two triangles: one for each half of the quad
    var indexData = [0, 1, 2, 0, 2, 3];
    var indexArray = new Uint16Array(indexData);
    var indexBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);
    gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indexArray, gl.STATIC_DRAW);
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null);

    var playButton = $("#playButton");

    var isPlaying = false;

    function startPlay() {
        isPlaying = true;
    }

    function stopPlay() {
        isPlaying = false;
    }

    playButton.click(function () {
        if (isPlaying) {
            stopPlay();
        } else {
            startPlay();
        }
    });

    function onVolumeChange() {
        gainNode.gain.value = this.value;
    }

    document.getElementById("volume").addEventListener("change", onVolumeChange);
    gainNode.gain.value = 1.0;

    function onBassChange() {
        bass.gain.value = this.value;
    }
    document.getElementById("bass").addEventListener("change", onBassChange);
    bass.gain.value = 1.0;

    function onTrebleChange() {
        treble.gain.value = this.value;
    }
    document.getElementById("treble").addEventListener("change", onTrebleChange);
    treble.gain.value = 1.0;

	floorImage = new Image();
	floorImage.onload = function() {
		// Step 1: Create the texture object.
		floorTexture = gl.createTexture();
		// Step 2: Bind the texture object to the "target" TEXTURE_2D
		gl.bindTexture(gl.TEXTURE_2D, floorTexture);
		// Step 3: (Optional) Tell WebGL that pixels are flipped vertically,
		//         so that we don't have to deal with flipping the y-coordinate.
		gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
		// Step 4: Download the image data to the GPU.
		gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, floorImage);
		// Step 5: (Optional) Create a mipmap so that the texture can be anti-aliased.
		gl.generateMipmap(gl.TEXTURE_2D);
		// Step 6: Clean up.  Tell WebGL that we are done with the target.
		gl.bindTexture(gl.TEXTURE_2D, null);
	};
	floorImage.src = "img/"+(time.getUTCMinutes()%12)+".jpg";


</script>
    <h2>Team Members</h2>

    <ul>
        <li>Please list your team members with NetID in this unordered list.</li>
        <li>Josh Beinhacker (jpb345), Aishwarya Singh (as2539), Alex Schneider (aas339), Spencer Weiss (sbw66)</li>
    </ul>
</div>
<video id='v' muted style="position:absolute;visibility:hidden;top:0;left:0;"></video>
<canvas id='c' width="512" height="512" style="position:absolute;visibility:hidden;top:0;left:0;"></canvas>
<script>
v.addEventListener('play', function() {
   con = c.getContext('2d');
   // Ratio is actually 1.33:1, but store as power-of-two for webgl and fix in shader
   w = 512; h = 512;
   setInterval(function() {
      if (v.paused || v.ended) return;
      con.fillRect(0, 0, w, h);
      con.drawImage(v, 0, 0, w, h);
      imageData = con.getImageData(0, 0, w, h);
      webcamTexture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, webcamTexture);
      gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
      gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, imageData);
      gl.generateMipmap(gl.TEXTURE_2D);
      gl.bindTexture(gl.TEXTURE_2D, null);
   }, 33);
}, false);
$("#inputMode").change(function() {
    console.log("I am here");
    micSource.disconnect();
    fileSource.disconnect();
    if (document.getElementById("inputMode").value == "microphone") {
analyser
        micSource.connect(analyser);
    } else {
        fileSource.connect(analyser);
    }
});
</script>
</body>
</html>
